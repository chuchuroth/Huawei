您好，根据您的请求，我已对提供的讲解字幕内容进行了合理的断句和标点，使其更加流畅和通顺。

***

**自动驾驶的”端到端“AI新春天：依然分裂、冲突、孤注一掷**

**第一部分：行业现状与端到端技术的初现**

无人驾驶真的能落地吗？人类从 1921 年提出无人驾驶的幻想，到研发推进，已经消耗了无数的时间与资金。花了那么多钱，但是实际上这些钱有多少是用在探索上的？到了今天，事故频发、烧钱无止境、进度缓慢，引发了众多的不解与质疑：无人驾驶是否是一场骗局，甚至行业已死？

这个行业真的是我见过最分裂的行业之一了。各个派系的观点各不相同，互相瞧不上，互相指责。那神仙打架之后啊，又各干各的，各踩各的坑，各倒各的霉，各花各的钱。那么结果就是在 2024 年之前啊，无人驾驶走入了寒冬，革命进入了低潮期啊。但是呢，这个寒冬啊，到了 2024 年，因为马斯克的高调入局，似乎呢又出现了一些新的生机和希望。

2024 年上半年，特斯拉开始陆续更新自动驾驶系统 FSD 的 V12 版本，号称通过端到端 AI 技术，给自动驾驶带来了第二个春天。那公众能够感知到特斯拉 FSD 的效果确实比之前的好了一大截。但在我们试驾的过程当中，依然出现了好几次比较惊险的、需要人为接管的情况。但这丝毫**不**影响马斯克信心大增，宣布要在今年 8 月 8 号发布特斯拉的 Robotaxi。话说马斯克早在 2019 年就承诺，特斯拉在 2020 年会拥有 100 万辆无人驾驶出租车。可能马斯克“狼来了”惯了，所以 8 月 8 号这个听起来不太实际的日期，也没有被业内人士当真。

“我不认为 8 月 8 号会落地，这个可能性基本为零”。果然，特斯拉 Robotaxi 的发布会啊是再次的延后了。那这一次呢是延期到 了 10 月 10 号。我们在等待马斯克给出的这个新的时间点上，他会不会再一次的放鸽子的同时，我们硅谷 101 想再次的探寻一下自动驾驶技术的发展现状。特别是让马斯克信心倍增的端到端技术，算自动驾驶界的 ChatGPT Moment 吗？

“我是同意这个观点。”“我个人也非**常**同意。”“我非常同意你说这个观点。”

端到端能否带领我们走向真正的无人驾驶呢？“我觉得这个算法是不成熟。”“我觉得还没有达到 L4 的标准。”自动驾驶中定义的 L2 与 L4 之间真的相隔甚远吗？“今天的特斯拉的 FSD 已经距离 L4 已经非常非常接近了。”“咱们不要追假圈粉，FSD 叫辅助驾驶，它不是无人驾驶。”“当我觉得并不是说我们的技术路线或者技术深度会比 L2 高。”

如今无人驾驶技术发展到哪一步了？“这个技术我觉得是接近于很成熟的一个状态。”“对于整个行业而言，我从来没有这么乐观的估计。”纯视觉与多模态之争真的没有尽头吗？“可能大家殊途同归。”

为了探究无人驾驶行业到底发展如何，我们历时三个月，采访了全球市场上最前沿的无人驾驶公司，包括 Waymo、Cruise 的前核心员工、前特斯拉 FSD 工程师、以及二级市场投资人等多达十多位自动驾驶界的专业人士。我们原本希望得到一个确定的答案，却发现这个行业依然还是那个割裂的行业。在很多技术路线的选择上，业内并没有达成共识。而非共识的科技前沿，正是我们硅谷 101 最感兴趣去探索的方向。

这些视频我们将从感知、算法、产品、运营、经济、还有法律等等多个角度，全方位一起来讨论一下如今的自动驾驶技术最前沿的现状。那么这期视频啊，我们分为了上下两集，确实有点长啊。但是呢，看完之后，相信会让大家对这个行业的最新进展拥有更全面的认知。那么接下来就让我们开始吧。

**第二部分：概念区分与感知技术路线之争**

首先我们来做一个概念区分：**无人驾驶和自动驾驶的区别是什么呢**？

根据智能化程度的不同，自动驾驶被分为 L0 到 L5 共六个等级。
*   L0 为无自动化。
*   L1 指驾驶援助。
*   L2 指部分自动驾驶。
*   L3 指有条件自动驾驶。
*   L4 指高度自动驾驶。
*   L5 指完全自动驾驶，即真正的无人驾驶。

我们之后在视频中提到的 Waymo 和 Cruise，以及胡小迪做的无人卡车，都属于 L4 级别。特斯拉 FSD 属于 L2 级别。但马斯克号称将要做**的**特斯拉 Robotaxi 却是 L4 级别的。所以目前在这个产业当中啊，人们说无人驾驶一般就指的是 L4 的公司，因为现在还没有人能够做到 L5。而一般说自动驾驶则是包括了所有的 Level，是更加泛的一个称呼。

好了，这个区别我们了解之后呢，再来看一下自动驾驶产业是怎么开始的。尽管早在 100 年前人类就开始探索无人驾驶，但是公认现代自动驾驶正是起源于 2004 年美国军方的 DARPA 挑战赛。经过了几年的发展之后，形成了感知（Perception）、规划、控制（Control）这样的运行链路。

其中，感知模块包括了感知和预测。感知层需要通过雷达、摄像头等传感器获取前方路况，并且预测物体的运动轨迹，实时生成一张周围环境的地图，也就是我们在车上常见的鸟瞰图。再将这些信息传递给规划层，由系统根据算法来决定速度和方向。最终在下方到执行层，控制应对的油门、制动和转向机。

后来随着 AI 的兴起，人们开始让机器自己去学习如何开车。先让算法到仿真的数字世界里面开车。等仿真训练到一定的程度，就可以开始上路测试。而最近这两年啊，随着特斯拉端到端方案应用在 FSD V12 的版本当中，感知、决策、控制的运行链路呢，也开始改变。那这点我们在后面分析端到端的时候会讲到。

接下来我们重点来聊聊自动驾驶产业在感知这个层面的两派技术路线：**纯视觉派与多模态融合派**。那么这两个派别在过去很多年一直在打架，各说各的好，我们就来讲讲他们的恩怨情仇。

目前汽车主流的感知方案分为两种。

**第一种是不少公司采用的多模态融合感知方案**。会将激光雷达、毫米波雷达、超声波传感器、摄像头、惯性测量单元等传感器采集的信息进行汇总融合，来判断周围环境。回到我们上一章说到的 DARPA 挑战赛。2004 年第一届当中啊，虽然没有任何一辆车完赛，但是呢，一位叫做 David H 的参赛者在比赛当中意识到了激光雷达的重要性。在比赛结束之后，他创办的 Velodyne 公司，开始从做音响转向了做激光雷达。当时的激光雷达还是单线扫描，只能对着一个方向测距。而 David H 就发明了 64 线机械旋转式激光雷达，可以 360 度扫描环境。

后来他带着这台旋转式的激光雷达参加了 2005 年的第二届 DARPA 挑战赛。那终于啊有台头顶着五个激光雷达的车完赛，并且取得了冠军。但这不是 David H 的车，他的车辆中途因为机械故障而退赛了。不过他的表现确实让大家意识到了激光雷达确实是个外挂。那么到了 2007 年的第三届 DARPA 挑战赛当中，完赛的六支队伍当中五支都用到了 Velodyne 的激光雷达。至此，激光雷达开始成为自动驾驶界的香饽饽，Velodyne 也成为了车载激光雷达的龙头企业。

“因为现在不管是 Cruise、Waymo 基于 L4 在做的一些 Solution，都是基于激光雷达为主的。然后他可以直接拿到位置信息，这样的话对于算法本身的要求就是相对会比较低一些。然后可以很多直接通过 Sensor 来达到这些 3D 的信息，这样对系统的鲁棒性，还有对于安全性、Corner Case 会比较轻松。”

**另一个技术派别就是以特斯拉为代表的纯视觉方案了**。靠摄像头采集环境信息，然后利用神经网络将 2D 的视频转换为 3D 的地图。其中就包含了周边环境的障碍物、预测的轨迹、速度等信息。相比激光雷达方案直接生成 3D 地图，纯视觉是多了一道 2D 转 3D 的过程。

那在张行看来啊，单靠视频这种缺乏 3D 信息的训练数据会给安全性带来一定的挑战。他“就需要大量的纯 Data 去学出这样一个缺乏 3D 的信息。这样的话，我们缺乏一个 Supervision，因为没有一个参照物，很难去拿到一个现实中的一个 Ground Truth。这样的话，如果完全去通过这种非监督的学习方式，想要达到系统的安全性，我觉得是比较难的。”“我觉得主要一个目的还是控制成本。”

但是在特斯拉的前 AI 工程师俞正华看来，选择纯视觉路线并不只是节约成本那么简单。其实特斯拉原来的辅助驾驶系统是有毫米波雷达去融合的。他认为“一个很复杂的算法就是他做坏的，并不一定好。”俞正华的车在 2023 年进行了一次保养，Service 工程师自动把雷达去除了。他认为“去掉毫米波雷达不是为了成本。主要根源的原因是纯视觉已经胜过毫米波雷达了。所以特斯拉是在做减法，把一些他认为不需要的冗余的事情去掉，或者说累赘的事情去掉。”

俞正华就认为啊，如果融合算法做不好，或者呢通过纯视觉就已经能够达到足够好的效果了，那么更多的传感器反而成为了累赘。接着我们采访的很多 L4 从业者也同意信息并不是越多越好。反之呢，传感器收集到了太多额外的无效信息，会加剧算法的负担。

**马斯克一直倡导的，光靠摄像头这一种传感器到底行不行呢**？马斯克就说了，既然人类仅通过两只眼睛就能够开车，那么汽车也可以仅凭借图像信息来实现自动驾驶。但是业内对于纯视觉派的担心一直是视觉欺骗。这在过去也确实带来了不少事故。比如说特斯拉将白色卡车识别为天空，把月亮识别为黄灯。又或者理想把广告牌上的内容识别为汽车，导致高速急刹、追尾等事故。这些案例是否意味着少了深度信息的纯视觉方案存在着先天性不足呢？

“多个信息流确实能够给你提供更多的信息，但是你要解答一个问题，就是是摄像头本身难道它的信息不够吗？还是你的算法去挖掘它信息的算法能力不足？”

俞正华不认为视觉欺骗的根本原因是摄像头的**信息**不足够，而是算法不足以处理或者挖掘摄像头给的信息。他认为，特别是在特斯拉 FSD V12 算法推出之后呢，更加证明了当算法得到了巨大的优化，那么摄像头信息的挖掘和处理就能够得到明显的进步。

“今天的 V12 它不是完美的，有很多的问题，但是我到目前为止没有发现哪一个问题是由于传感器的不足。当然在 V12 之前，确实我很多很多是由于传感器不足，但今天 V12 没有这个问题。”

但是呢，L4 的从业人员就有不同的观点了。他们认为摄像头就是有天然劣势的。从**事** L4 研究的张行就认为，摄像头无法与人眼媲美，主要原因是在于摄像头的焦距和像素呢是固定的。而人眼的精度非常高，并且可以自动变焦。同时人类跳跃式的思考模式短期之内也无法应用在计算机上。所以使用激光雷达才能够补充摄像头的缺陷。

但是市面上也有其他的看法，认为就算除了视觉信息，其他的传感器也会带来干扰信息。比如说激光雷达也存在自己的缺陷。由于是通过激光测距，在面对一些反射物体、雨雪天气或者其他车发射的激光的时候，会对激光雷达带来干扰，最终造成幻觉效应。

“我是非常坚定的纯视觉派。这个世界的道路都是给人**和**视觉设计的。也就是说除了视觉之外，你采集的信息你可以认为都是 Noise。当然你可以采集到，但是那些信息提供的 Noise 和它提供的真正的价值，到底最终是什么样的分布？我觉得在视觉越做越好的情况下，可能反而是完全相反的。”

如果能做好多传感器融合算法，让激光雷达与图像信息互相验证，或许会让系统的安全性更进一步的提升。胡小迪就提出了一个形象的类比：两个同等水平的学霸在考试的时候，最终一定是使用计算器的学霸会更轻松，只是经济基础决定了买不买得起计算器而已。

那么是选择纯视觉还是选择以激光雷达为主的多模态融合方案？这个辩论啊已经持续了数年，并且似乎短期内也不会有共识的答案。或者呢，对于一些创业公司来说，什么路线根本也没有那么重要，而成本和经济账才是最重要的。

“我曾经被认为是视觉派的，是因为当时买不到激光雷达呀，所以逼着我们不得不去在视觉上多去找解决方案。我也不反对激光雷达，激光雷达便宜了，第一个去排队。激光雷达确实便宜了，所以我也在排队买激光雷达。那对我来讲就是抓着耗子都是好猫。那我们只要这个设备的成本足够低，只要这个设备能从信息论意义上给我们提供有足够有价值的信息，我们就该去用它。”

中国的自动驾驶圈很快的就把这些硬件，比如说激光雷达、毫米波雷达，做成了白菜价。那么在这种状态下，是不是还要维持像特斯拉那样做纯视觉？其实很多公司现在就在犹豫了。那我是 1000 多块钱买一个固态激光雷达，还是说我用纯视觉，但是对算力上会造成很大的浪费？

“我觉得 1000 块钱太贵了，特斯拉连雨量传感器都不舍得用。”

但是，随着供应链 Scale 的上升，成本的大幅下降，在激光雷达能做到和一个摄像头相似的价**格**的时候，特别是在端到端的这样一个应用场景下，是不是纯视觉还是一个唯一的路径？

有意思的是啊，随着激光雷达价格大幅度的下降，业内开始对特斯拉即将发布的无人驾驶出租车是否会用上激光雷达产生了分歧。比如张行就认为，由于 Robotaxi 没有人类干预，而且出了事呢需要企业负责，那么特斯拉可能会选择更加保守的路线，会用上曾经瞧不上的激光雷达。特别是他需要去为这些事故负责的时候，他需要更加的保守。

“我觉得他是可能是非常需要这样一个额外 Sensor。从这个角度看的话，我觉得就是 Tesla 可能会采取一些它之前鄙视的一些技术，只要这个东西有用，能达到 L4 的目的，它会逐渐去采用了。”“最近我们也发现特斯拉他在做这个 L4、L5 的一些方面也在考虑，他也在跟这个激光雷达的一些厂商也在聊一些合作。”所以说可能就是大家殊途同归。

今年激光雷达制造商 Luminar 发布了第一季度的财报，显示特斯拉的订单达到了 10%，成为了最大的客户。而俞正华却不以为然，认为这并非是什么新鲜事。

“首先他肯定不是为了以后量产车上使用激光雷达。因为这个 Luminar 它这个第一季度好像是 20 个 M 它的总收入，然后 10% 的话就是 2M，2M 里也不够装几个激光雷达。特斯拉其实它的工程车上、测试车上装激光雷达大家都已经发现了，这不是什么秘密了。那个激光雷达呢，主要就是用来采集这个训练神经网络的 Ground Truth。”

“人工是无法标注那个物体距离你有几米这个事情，你必须要用专门的传感器来进行标注。但是这个 Luminar 为什么在第一季度来披露这件事情，我其实也非常 Confuse。因为马斯克当时就回应了嘛，说我们叫 V12 之后呢，我们不需要这个 Ground Truth 了。因为是这个 End-to-End 了，这个占**用**网络是一个是 V11 的一个时代的事情。我可能觉得这里面有一些误解，就是从这个财报上，或者说它财务规则上。”

虽然目前不确定特斯拉即将推出的 Robotaxi 是否会搭载激光雷达，但是有一点可以确定的是，以目前特斯拉的感知配置，安全性还不足以达到 L4 或者能运行 Robotaxi 的程度。

“我非常确定现有的特斯拉的这几个车型都有非常非常明确的盲区，就是视觉不可达的盲区。而这个盲区就造成如果他想实现最终的不管是 L4、L5 的驾驶，它的下一款车一定需要解决这个盲区问题。”

关于特斯拉最新的端到端技术更新以及 10 月份将公布的 Robotaxi 细节猜测，我们会在第三和第四章节再详细地拆解。

**第三部分：高精地图与端到端算法的挑战**

那么接下来我们就来探讨一下感知上的另外一个重要的技术：**高精地图**。除了激光雷达之外呢，高精地图也是自动驾驶感知端当中的成本大头。高精地图就是提前去采集道路信息，降低感知模块绘制 3D 地图的压力，并且能提高准确性。

说来也巧啊，最早推行高精地图的人正是 2005 年第二届 DARPA 挑战赛的冠军，那个头顶了五台激光雷达的车主 Sebastian Thrun。在 2004 年 DARPA 挑战赛的时候，谷歌正在筹备街景项目。谷歌创始人 Larry Page 亲自到了比赛现场去物色人才。在 2005 年比赛结束之后，Page 找上了 Sebastian Thrun，邀请他加入谷歌，并且将绘制地图的工作交给了他。在这个过程当中啊，Thrun 和 Page 突然就意识到，如果有一种能够精确记录所有的车道线、路标、信号灯等道路信息的地 图，那将会对无人驾驶带来巨大的帮助。这也奠定了高精地图在无人驾驶项目中的重要地位。

但是制作高精地图非常的昂贵。自动驾驶公司采集高精地图的平均成本大约是每公里 5000 美元。如果 要覆盖全美国 660 万公里的道路，光是采集成本就达到了 33 亿美元。再加上地图频繁的维护成本，最终消耗的将是无法想象的天文数字。

现在呢，已经有不少车企纷纷在宣传舍弃高精地图的“无图”方案，转而由车辆在本地固建环境地图。我们匿名采访的一位自动驾驶工程师就对我们表示啊，这些对比宣传更多的其实是出于商业模式的考量。对于做 Robotaxi 生意的企业来说，用上高精地图能够增加安全性。而对于车企来说呢，舍弃高精地图能够有效的降低成本。所以并不意味着舍弃高精地图技术水平就会更高。

“像特斯拉、华为还有那个什么理想，他们的解决方案是量产车的嘛？你的客户可能是来自各种城市，那就涉及到就是说你要在任何城市都能开。那现在主流的这个高精地图它的主要的门槛不是在于说就是它有需要有一个地图采集的这么一个过程。这个地图采集的过程实际 上是相对来说比较花时间人力成本的。然后它也需要专业的这个地图采集设备。所以你不可能就是在你如果是做这个量产车的生意的话，你不可能说我专**门**有一个地图采集车，我把全中国都给你跑遍了，对吧？这个是不现实的。”

像特斯拉、华为、理想等 L2 的公司抛弃高精地图，是因为无法覆盖每一条大街小巷。而 Waymo、Cruise 这样做 Robotaxi 的 L4 公司选择继续使用高精地图，是因为他们发现只需要覆盖一些关键的城市，就能拿下足够的市场了。所以是否使用高精地图成为了 Robotaxi 公司的经济账问题，而不是技术问题。

“如果你单看 Robotaxi 的这个 Business 的话，然后你把美国的这个 Robotaxi 的需求来划分的话，你会发现前五大的城市它已经占有了全美 1/3 的 Volume。不需要让它在全美任何一个地方都跑，其实你就已经有一个相当大的一个市场了。”

类似的，我们采访的另一位做 L4 自动驾驶卡车的嘉宾也分享到，他们如果要扩大运营路线，也就是扩充高精地图的覆盖范围，就得先衡量一下这条路线是否赚钱，否则呢也只是赔本赚吆喝。

那这么一圈聊下来啊，在感知端上，业内也没有统一的一个看法。就像胡小迪说的，“抓到耗子的就是好猫”。

**接下来我们再来重点聊聊大家最近非常关注的自动驾驶算法层面的最新进展**。特别是特斯拉进来大肆宣扬的端到端到底是个什么技术呢？它真的会改变自动驾驶的行业方向吗？

在视频开头啊，我们已经说到传统的自动驾驶的运行链路呢是先感知预测，再规划，最后再控制。
*   感知模块要先通过摄像头、雷达等传感器识别道路，把这些信息翻译成机器能够看懂的语言，传递给预测模块。
*   预测模块就会判断其他车辆、行人的行驶轨迹。
*   再把这些信息传递给规划模块，去找出风险最低的一条路。
*   最后再将控制信号传递给操控系统。

这时候的算法主要靠规则库（Rule-Base）来驱动。工程师需要不断写入各种的规则。比如说，遇到行人得减速，遇到红灯要停车等等。为了考虑各种情况，规则库就得尽可能的覆盖到各种的可能性，相应的代码也就非常非常长了。

**这样的算法有哪些难点呢**？最大的问题就在于系统被划分成了不同的模块，但是模块之间的信息传输啊会有所损失。如果下游无法拿到全面的信息，预测和规划的难度就会增加。

举个前线易懂的例子：大家都听过多**人**传话游戏吧？十个人从头到尾传递一句话，但经常这段话经过多人传递的过程，细节就会被丢失或者篡改，以至于到最后一个人那里的时候，意思就大相径庭了。那么类似的在传统的 Rule-Base 的模式下，如果上一层模块做的不够好，那么会直接影响到下一层的表现。

另外一个缺点是，规则都是由人工设计定义的。但是有限的规则无法去覆盖无限可能的现实情况。一些不常见并且容易被忽略的问题，机器就难以拿出应对的解决方案了。那么这被称为长尾问题（Long Tail Case），也被称为极端情况（Corner Case）。这就会导致规模化落地的成本非常高。

“还有就是在分两个模块的时候呢，我认为这个技术是很难 Scalable 的。为什么呢？你每次要在一个现实的复杂场景中，你如果新加一个 Task，那么你就要新加一些接口。新加接口，你就要去改变感知、改变控制、规划。比如说我们特斯拉，你举个例子，前几年 NHTSA 美国监管要求特斯拉能够检测到紧急车辆，就是 Emergency Vehicle，比如说消防车、救护车之类的。”

“你在感知上你就要要求要检测这个，然后呢控制、规划也要做这个。就这只是一个例子哦，这只是一个 Task。可能会成百上千这样的 Task 你要去 Scale。所以说在华为你们知道有几千个工程师，6000 个工程师好像是这样一个数据。为什么会要什么工程师？因为你会 有这么多不断涌现的新的 Task 出现，环境越复杂 Task 越多。我认为这不是一个 Scalable 模式。那这种方法还是比较老套，虽然说看起来如果做 Robotaxi 行业是比较零的一个方法论，但是它不能满足乘用车几百上千万台车将来在全世界的路面上行驶。”

**有什么样的办法能够解决这些问题呢**？这时候就得聊到端到端（End to End）了。

在自动驾驶领域内，目前主流的端到端定义是：传感器收集到的信息不加任何处理，传递给基于神经网络的大模型，并且直接输出控制结果。也就是说，不再需要人为编写各种规则，让算法跟着喂的数据自己学会如何开车。

“因为我们人类开车，我们脑子里并不是去判断某辆车的速度和角度的。你就是通过一个复杂环境来下意识来做出你的决策。这样算法更像人，因为人就是这样运转的。”这 样的思考逻辑正是马斯克带领特斯拉的前进方针。

那也就不奇怪啊，为什么端到端技术在驾驶里面并不新，但是却被特斯拉第一个做出来。虽然 2023 年底特斯拉才第一次将用上了端到端的 FSD V12 推出，但是在自动驾驶界，端到端并不是什么新鲜事。其实早在 2016 年，英伟达就有论文提出了端到端的概念。

现在端到端也分为两种：
1.  **分模块的端到端：** 是把部分模块替换成神经网络。这种分模块的端到端只是一种过渡形式，并不是完全体。因为各个模块之间需要传递信息，依然要定义各种接口，造成数据的损失。
2.  **纯正的端到端：** 在主流观点当中，只有将多个模块融为了一个整体，去掉了感知层、预测层、规划层这样的定义，才算纯正的端到端。

2023 年 CVPR 的最佳论文《Planning-oriented Autonomous Driving》就提出过，过去的端到端要么只运行在部分模块上，要么需要在系统中插入一些组件。而这篇论文提出了 UniAD 的模型架构，是首次将所有的感知、预测、规划模块都整合到了一个基于 Transformer 的端到端网络框架下。

相比传统这种 Rule-based 规则驱动的执行链路，端到端不再需要算法工程师去反复的完善规则库。所以才有了马斯克发布 FSD V12 的时候宣称的，其代码从 30 万行缩减到了 2000 行。

虽然自动驾驶当中端到端技术不是特斯拉发明的，但是特斯拉确实是第一家公司把这个神经网络端到端技术做出来，并且推向主流市场的。2023 年 11 月，特斯拉发布了 FSD V12 的第一个测试版本，但仅向选定的员工开放。到了 2024 年年初，特斯拉开始将 FSD V12 版本免费开放给美国地区的所有特斯拉车主，这意味着每位车主都有一个月的免费使用权。

FSD V12 推出之后呢，是一时间掀起了轩然大波。从用户体验上我们看到，大部分的舆论都认为比之前特斯拉 FSD 的进步非常之大，甚至很多人认为这是自动驾驶界的 ChatGPT Moment。

“真正让我觉得进步的是这个 Planning，就规划。比如说过环岛，因为这个过环岛其实是在传统的 Planning 方向上是挺难做的。因为你要面对前面的车要 Cut In，然后你还要出去。这中间如何设置这种优先级？你即使设置优先级，那你跟前车和旁边的车保持多少的这种距离你才能出去？这是一个其实挺复杂的逻辑。但是这个在新版的 FSD 上表现确实让我觉得很惊艳，这是给我一个很大的惊喜。”

不少体验过 FSD V12 的人表示啊，这个通过人类驾驶数据来学习的系统，驾驶风格非常像人，不再有机械式算法带来的顿挫感。但是与此同时，也有嘉宾在体验之后认为 FSD V12 还没有好用到让人非用不可，与 L4 之间呢还存在着一定的差距。

“但是呢，他没有好到那个 GPT-4 的那个 Moment，就没有好的说这个东西让我说我必须得用，或者是 我立马就要用，我能够非常在我的很多的场景里面去用。所以相对它的表现还是比较好的。但在 Local Road 上，我觉得基本上每开五个 Mile 左右，我觉得就需要 Disengage 一次。”

特别是“在 Unprotected Left，就是非保护性的左转，它还是比较容易去做一些让我觉得不是很安全的一些行为。如果你是这种 NPI 5 的话，那么你跟 Level 4 的自动驾驶还有一定的距离。”

从表现上来看，端到端的 FSD V12 依然还有进步的空间。但是从工程、运营和管理的角度来说，端到端的优势有以下的**三点**：
1.  **让系统整体更加简洁：** 去掉规则库之后，只需要不断补充训练案例，就可以进一步的提升模型的表现，维护和升级成本也将大幅度的降低。
2.  **节省人力成本：** 由于端到端不再依赖复杂的规则库，因此就不必去配备庞大的开发团队，甚至呢不用再依赖专家们。
3.  **实现更大范围的推广：** 目前 L4 的公司只能够在限定的地区运行。而抛开法规拍照的限制，是因为非端到端的方案需要针对具体地区去做优化。而端到端各个路况都能够应对，更像一个通用的司机。这也是为什么特斯拉 FSD V12 被比作 ChatGPT 的原因之一。

**既然端到端有如此多的优势，它能解决目前自动驾驶面临的技术问题吗**？

我们采访的不少嘉宾认为，在现阶段下进一步去发展端到端的路线是自动驾驶领域内公认的趋势，但是依然存在着不少的问题。

“这个方向是，我觉得是一个正确的方向。我们不可能通过一直在以打补丁的方式来做出一个 Scalable 的 L4 Solution。只不 过是目前我觉得我们要快速达到一个 L4 的 Solution 的话，也不可能完全通过端到端的 Solution。所以现在是一个矛盾的一个时间点了。”

**为什么目前的端到端距离 L4 还有一定的差距**？这就要从它的不确定性开始说起了。

端到端就像一个黑盒子，这就会带来比较多的不确定性。
*   比如工程师无法验证输入的数 据案例是否已经被模型学会。
*   或者遇到 Bug 的时候，无法定位到底是哪个环节出了问题。
*   又或者加入的数据是否会导致已经学到的知识被遗忘或者被覆盖。这种情况就被称为灾难性遗忘（Catastrophic Forgetting）。

比如说特斯拉的 FSD V12.4.2 的版本，内部其实早就做出来了，结果大规模推送却花 了很长时间。马斯克就解释到，因为喂的数据当中有很多人工接管的视频，反而让模型的水平出现了倒退。由于端到端的本质是模仿，如果遇到的情况恰好在训练数据当中有相似的案例，那就会表现的非常好。但如果超出了已有的参考案例，则会表现更差。也就是说，端到端对训练数据的数量和案例丰富性要求非常高。

“就是在交通路口红灯的时候，我们一定不**去**闯红灯，就这么一个简单的路。我觉得就是如果是 Heuristic Based 的，我们可以很简单的一个 if 就可以达到这样一个效果。但是如果是一个完全端到端的模型，它是完全 Fly Learnable 的。最后它要学**这**样一条路的话，其实是非常难的。所以我觉 得，短时间内端到端对 L4 是彻底的端到端还是有很大的 Gap。”

“我觉得这个算法是不成熟。你没有 Hardcode 所有的你设置的不能做的事情，他都可以尝试去做一下。于是就会在模拟里边就出现了很 多一头撞过去的现象。”

同时，端到端带来的还有**不可解释性**，这也是很多人担心的问题。所谓的不可解释性，就是改变其算法模型当中的任意一个权重节点或者层数，都会让模型的表现产生难以预测的影响。即使是模型的设计者或者训练者都无法知道中间的推理过程。与之相对的是可解释型。比如说在 Rule-Base 的模式下，工程师已经写入了当检测到塑料袋飘过的时候可以继续行驶的规则。那我们就不用担心遇到这种情况的时候会突然来个急刹车了。

“大家看到 V12 里头它在那个屏幕上的显示也好了很多。但是呢，如果你仔细想一下它所谓的端到端，这个显示从哪来的？如果这个显示来自于原来的这个模型，那牵扯的一个问题就是我们实际上在这个模型里边已经加了一层人为定义的接口，使得你可以从这个模型中的某一个位置提取出这个信息。”

“另一种我觉得是更恐怖的事情，就是这个显示是完全走了另外的一个路径。那就告**诉**的是车上显示说他看到前面有一辆大卡车，不代表它的模型真的认为前面有一辆大卡车，就是用来做控制的模 型前面真的有辆大卡车。如果这一点也被破坏了，那将是非常非常恐怖的。就说是你看他前面看到有辆车，但是他也有可能虽然说概率非常小，但是你现在不能确定说他是不会撞上去的。”

“他是否是真正的端到端？我实际有点怀疑。或者说也许不是怀疑，但是就是说这里边可能有别的危险性。”

对于像自动驾驶这个对于安全系数要求这么高的行业来说，端到端模型带来的不可解释性是不是硬币的另外一面？由于目前特斯拉还没有完全公布 FSD V12 的技术，我们并不知道 FSD 是否采用了多模块的策略。但是我们发现已经有车主遇到了画面显示与实际行为不符的案例。比如在 YouTube 上面的这段视频，车辆构建的鸟瞰图显示前方有人，但是却没有表现出任何刹车的痕迹，而是继续行驶过去。索性啊只是感知端的误减，没有发生事故。这个案例虽然可以看出在端到端算法下，上层错误不会影响下层决策的优势，但是也表现了规划层偶尔会不认可感知层的结果，是应证了刘冰燕的担忧。

**不可解释性是否会成为阻碍端到端发展的一大难题呢**？接下来就是我们看到的第三个冲突了。

“我认为是这样的，就是 AI 的一个很严重的问题就是它在理论的性是远远之后的。没有告诉你这个一定 Work，一定不 Work。所以说它是一个实验性的学科，都不算科学，我认为是一个实验性的学科，就需要一个大量的验证。”“V12 是全面碾压 V11。所以说这是结果说话的一个问题。那难道你还会想，哎，端到端有这个不可解释性那什么什么什么？因为他全面碾压，对吧？那就是一个非常无脑的，你就应该往下走。”

俞正华就认为 AI 作为实验性的学科，只要结果达到了预期，就能够证明方向正确，应该继续的推进。

而胡小迪表示呢，V12 表现大幅度领先于 V11，只是因为 V11 的基础太差，而表现距离真正的无人驾驶还比较远。

“如果真的是 Full Self Driving 以 L5 来去限制的话，他一定要过一些监管部门，他们需要有一个可解释性或者可预测性。再**加**上对于世界上有这么多的城市，就在美国来说，他每个城市他可能都会有不一样的法律法规。这个车无论从硬件软件上是不是需要去适应当地的法律法规，变成了能不能 Scale 的一个很大的问题。”

端到端不能通过人为定义规则来对模型进行微调，所以能否适应不同法规成为了端到端规模化的一个挑战。同样影响规模化的因素在于端到端对数据量和传感器更加的敏感。

“端到端有一个非常严酷的问题，就是它对 Sensor 对传感器会更敏感。也就是说当你换了传感器或者换了传感器的分布的时候，你这个模型可以说是完**全**重头学。”

从另一个角度来说，工程上不可接受，或者说我们无法想象之后全世界路上跑的都是同一款车。一旦更改了传感器的分布，就会让模型失效，得重新开始训练。那为了训练又得采集大量的数 据，必然会带来巨大的成本。美国财经媒体 CNBC 就报道称啊，到 2023 年年初，为了训练特斯拉 FSD，就用到了 1000 多万段特斯拉车主的驾驶视频。而且这 1000 万多段的训练数据可不是随便使用的。必须是驾驶水平比较高的人类司 机，否则呢只会让模型的水平越来越差。所以训练端到端的模型不光要求数据多，还得经过复杂的筛选。那么这个过程中又得消耗大量的人力。对于卖车多的特斯拉可能不在话下，但是对于其他公司来说，数据来源却成为了大问题。

“很多主机厂因为盲目的追求特斯拉那套方法论，导致有点被忽悠瘸了。这套东西确实不适合 90% 的主机厂。”

这是不是意味着其他的厂商真的无法进入端到端的领域呢？虽然英伟达和特斯拉都是通过纯视觉来驱动端到端算法运行，但是端到端实际上也可以接受多模态输入。目前常用的毫米波雷达、激光雷达、超声波雷达等传感器在车辆上的位置相对固定，特别是激光雷达基本上都在车顶上。所以采用多模态接入的端到端就能利用不同车型采集的数据来训练模型，而且留给主机厂的设计空间也会更大。

**这么一圈聊下来，我们发现每种算法都各有千秋**。哪种方式能够带我们彻底走向全无人驾驶的未来依然不明朗。

“不觉得在当下有一个任何一个算法能有简单又 Scalable，然后呢又 能达到 L4 标准。”“我觉得这个算法本身是不存在的。这个领域是一个大家一起去推动的，我觉得我是非常乐观，大家会殊途同归，虽然大家会稍稍有一点点不同的偏差。”

无论是哪种算法，最终要面对的是**长尾问题**。在传统 Rule-Base 的规则驱动模型下，编写规则库需要庞大的团队，消耗大量的精力，而且还很难做到面面俱到。那么有了端到端之后，长尾问题能够得到解决吗？“他解决了 General 的 Case，但是长尾的问题我觉得一定会存在。”

有人认为自动驾驶系统的容错率很低，如果要将一个黑盒系统用在 L4 上，那么就必须引入其他的安全机制。但是这样又回到了 Rule-Base 模式下的成本问题。

开头我们也说到自动驾驶算法会先到仿真系统里面练习。那仿真训练可以解决一定的长尾问题吗？“目前还没有一个很好的方案能通过生成的这个 Simulation Data，能够对我们的这个现实中的这个 Real Behavior 有真正有很大的帮助。”

“像自动驾驶或者机器人 的领域里面，这个环境是非常非常复杂的。就是你要仿真的话，你仿真的不只是你自己这个车会未来怎么动。主要困难的是当你自己的车的轨迹发生变化的时候，你会影响周围的所有的车和人的行为也发生变化。然后就是如何能够很好的仿真，并且能够不出现 Distribution Shift，我觉得依旧是一个 Open Topic。”

既然虚拟的场景无法完全模拟出真实的这种可能，那么这是不是意味着目前业内没有办法解决长尾问题，只能靠漫长的积累经验呢？

“某种程**度**上是吧。你也不用做到就是特别完美，对吧？人类也不完**美**，你就是要做的比人好就行。人也有他 的失误率吧，你只要做比这个好就够了。”

“我觉得长尾问题其实也是一个伪命题啊。在 我看来呢，长尾问题比如说我见到鳄鱼怎么处理，我见到大象怎么处理，我见到一个固定**的**飞机停在高速公路上我怎么处理？这些事情大家都觉得是长尾问题。但是实际上对于很多长尾问题，我们是把他包裹成一大类问题的。就见到我没见过的物体，我不知道是什么东西，它有一坨东西在我的前进路径上，我怎么处理？这种如果你把它包裹成了一个更 General 的一类问题的话，它是很好处理的。比如说我们曾经就见到有固定**的**飞机停在高速公路上。那我们的处理方法很简单：停车呀，对吧？”

而长尾问题到底是不是伪命题，或者它是不是需要解决的问题？这个话题可能大家都有自己的答案。而长尾问题对应的是 L4 甚至 L5 何时才能够大范围的铺开。

**第四部分：L2 与 L4 的激烈冲突**

所以接下来我们再来看看 L2 和 L4 的激烈冲突。我们在马斯克宣布推迟发布 Robotaxi 之前就询问了各位嘉宾的看法，大家对此的看法非常统一：那就是今年特斯拉的无人出租车是不可能上线的。大家观点如此统一的最大原因，就是在 于目前特斯拉已有的车型达不到 L4 标准的无人出租车。

“我非常确定现有的特斯拉的这几个车型都有非常非常明确的盲区。如果他想实现最终的不管是 L4、L5 的自动驾驶，它的下一款车一定需要解决这个盲区问题。”“而解决这个盲区问题，回到我们刚才说的，它一定要调整相机传感器 的位置。而调整这些位置立刻带来的结果就是之前这个模型会完全失效。就是现有的车从视觉、摄像头架构的角度来说，是不可能达到可以完全无人接管的 FSD 的。从这个角度来说，它必须有一款新的硬件出现。”

在业内人士都不看好的情况下，是什么原因让马斯克对推出 Robotaxi 如此有信心呢？“我认为主要呢还是这个 V12 的几个技术突破。作为马斯克他的这个性格，他看到 V12 今天这一刻在他的这个计划里面，他就觉得 Robotaxi 应该必须摆上日程了。”

**所以 FSD V12 能够让特斯拉走向 L4，承担起 Robotaxi 的重任吗**？和目前已有的 Waymo 或者 Cruise 相比起来差距有多大呢？

在采访胡小迪这个问题的时候，他的回答让我们看到了行业内的另外一派的观点：**就是 L2 和 L4 的差距非常远**。

“首先特斯拉做的不是无人驾驶。你看我刚才说了，我们今天谈的是去掉人，并且由软件开发公司承担责任的方案，才叫无人驾驶。咱们不要虚假宣传，FSD 叫辅助驾驶，它不是无人驾驶，所以做的不是一个东西。”

目前被广泛应用在车企上的都是 L2 辅助驾驶，比如说特斯拉、小米、华为等等。而像 Waymo、Cruise、百度这样作无人出租车的企业则采用的是 L4 高度自动驾驶。抛开书面的概念定义，这两者之间的本质区别就在**谁来承担责任**。

“去掉人，并且由软件开发公司承担责任的方案才叫无人驾驶。”“讲个笑话，如果特斯拉撞死人了怎么办？对 Elon Musk 来讲 Not My Business。”所以如果特斯拉想做无人出租车，就必须做到自己承担责任。

**那辅助驾驶和自动驾驶之间从技术上又有哪些区别呢**？

L4 无人驾驶要解决的核心问题是什么？是**安全性、冗余性**。就是当一个系统的每一个模块都有可能会失效的时候，这个系统还仍然能够保障最底线的安全，这件事情还是最难和最关键的部分。L4 在之前要先解决安全性的问题，但是这件事情根本不是特斯拉的设计宗旨。

另外一位 L4 自动驾驶研究员也分别从硬件和软件的角度分析了 L2 和 L4 之间的区别。

“L4 的这个解决方案首先是我们有比较强的 Sensor。这个可能很难在 L2 场景里面去用，起码不会用这么高精度**的**雷达。”

“但是它从算法角度呢，可能 L2 公司更注重的是一些更高效能，能把成本降的很低，然**后**不需要特别昂贵的 Sensor，然后可能能更少的 Compute 就可以达到这样一个效果。这 L2 其实不需要考虑这种百万分之一的 Case。那 L4 追求的是 1M Mile 以上才需要引入一次的这个 Human 的这个 Remote Assistant。就是达到追求的是这种百万分之一的 Case。”

**我们来总结一下**：
*   L4 的方案采用的传感器精度更高，芯片的算力会更加充足，也能够应对的场景更加的全面。
*   但 L2 的方案当中首先要考虑的是成本问题，所以硬件水平会稍低一些。同时呢，算法为了适应水平稍低的硬件，会更加的注重效率而非安全。

这样来说呢，L2 的接管频率就会比 L4 高很多。

**那么像特斯拉这样作 L2 的公司能否通过提升硬件与软件来达到 L4 的效果呢**？

“我不支持 L2 进化到 L4。我觉**得**这件事情又是一个带有很强这种外推属性的伪命题，对吧？就是**说**假以时日海豚能不能进化出文明来？我觉得有可能，但是我们要知道地球文明已经容不下海豚去进化了。因为已经有公司做出来了。我这个公司就是为了能够最快速的 L4 落地。我落地以后就没你什么事了，对吧？智人拿起这个标枪的时候，就没有海豚去产生文明什么事了。”

在胡小迪看来，目前已有的 L4 公司已经筑起了技术壁垒了。在激烈的竞争之下，是不会给到 L2 公司进化的机会的。

同时呢，也有人认为这并不意味着 L4 的技术就比 L2 更加的高级，只是大家针对的场景的不同。

“如果说真的 L4 比 L2 像大家所想象的在技术上是绝对的高级，绝对的领先，那么我想请问为什么 L4 技术不能够直接降级成 L2？事实上是在过去的很多年里面，L4 公司呢被迫由于他这个收入的压力，他都在帮车厂去做 L2。但它不能够简单的降级，它基本上都要重新开发。那我们也知道在美国 GM 是拥有 Cruise 公司，福特呢是拥有 Argo AI，也是个 L4 公司。为什么 GM 不能使用 Cruise 的技术在他的量产车上？为什么福特不能使用 Argo 技术在他的量产车上？所以说 L4 并不是比 L2 绝对高级。在技术难度上，我不认为你你做 L4 了你就显得你非常非常高级。”

**那为什么 L4 的技术不能够直接降级成为 L2 使用呢**？张行对此解释说，由于 L4 所采用的硬件规格更高，而 L2 的算法必须要适应规格更低的传感器和算力较少的处理器，才导致两者的技术无法直接的迁移。举一个例子，就像一位建筑设计师，他被没收了电脑，只给他精度不高的尺规和纸笔，那他也得重新适应一下新的画图方式。

“就是你前面说的就是这个计算量的问题。L2 的这个 Solution 不可能去支持我们在一个车的后备箱里面放一个 Supercomputer。其**实**是一个不现实的一个解决方案。”

同时呢，张行对于 L2 和 L4 的技术比较也是表现出了更加开放的心态。L2 覆盖的范围更广，需要面对的场景更多，只需要解决基本的问题就可以。而 L4 的覆盖范围有限，所以关注各种细节。所以呢，两者之间也是各有优劣的。

“L4 本身不能通过简单的去把已有的系统做简化去**冗**余，就简单的去做一个 L2 的 Solution。但反之亦然，对我们 L2 想做到 L4 的标准，这是一个很长的时间去磨练。包括你需要很长时间的数据收集，然后去积累。但我觉得并不是说我们的技术路线或者技术深度会比 L2 高。我觉得这个不一定。可能很多并不是说很尖端的一些算法，但是就是通过一些很细心的去 Debugging 去解决这些很细节的些长尾问题。”

“我觉 得就是在普通的大众，甚至一些 L4 公司呢，会给大家灌输一个概念就是 L4 技术优于 L3，然后优于 L2。我觉得这是一个脱开它的限制场景来误导大众。”“我个人觉得就是还是会看 L4 的公司吧。因为就是这个逻辑上来说 L4 是可以降维打击的。而 L2 的话，如果你只做这个你是升不上去的，或者说非常非常难升上去。其实在技术**战**上，我觉得就没有说一个特别二元的一个门槛吧。就比如说某家公司他今天他说他可以 Claim 他做 L2 的公司，那也许他明天他加了一些新的技术，他也可以去做 L4，对吧？就完全看他用采用什么技术，或者说什么新的科技突破，对吧？”

“我再 说一遍：辅助驾驶、无人驾驶这两个东西。”

那由于视频长度的原因啊，我们把自动驾驶的运营、商业化、还有宏观经济对自动驾驶行业的影响以及投资人如何看待特斯拉股价等等内容放到了下期的节目当中，很快就会上线了。大家别忘了关注我们的频道。

另外，我们硅谷 101 团队将会在今年 10 月 19 号在硅谷举办一场 800 人左右的 AI 大会。其中也会请到行业资深人士来到现场，分享自动驾驶最前沿技术的见解。那目前确定参与的就包括了小马智行 Pony.ai 的联合创始人兼 CTO 楼天成，以及图森未来的前联合创始人 CEO，现 Beep Auto 的创始人胡小迪等等，会非常的精彩。

感谢大家对我们硅谷 101 的支持，你们的留言、点赞和转发是支持我们做好深度技术和商业内容的最佳动力。那我们下期视频啊，接着聊自动驾驶的运营和经济篇。那我们下次再见了，拜！
